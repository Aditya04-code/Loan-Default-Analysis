{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# FIN42100 Machine Learning in Finance: Predicting Loan Default\n","\n","## Group No : 4\n","\n","**Group Members**:\n","<br>\n","Tejaswi Patil - 24209396 <br>\n","Shagun Chandok - 24289312 <br>\n","Nilay Singh - 24289944 <br>\n","Dhruv Singh - 24234646 <br>\n","Aditya Suhane - 24212188 <br>\n","  \n","**Submission Date**: April 18th  \n","\n"],"metadata":{"id":"PLfC3iU5Ls7P"}},{"cell_type":"markdown","source":["## Question 1: Exploratory Data Analysis and Insights\n","Objective: Conduct comprehensive data exploration to uncover patterns and insights relevant to predicting loan defaults."],"metadata":{"id":"CcbDf8w0RskG"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.preprocessing import LabelEncoder\n","from scipy.stats import chi2_contingency\n","\n","\n","df = pd.read_csv(\"C:/Users/adity/OneDrive/Desktop/clg/UCD/Sem 2/ML For Finance/Project/SBAnational_clean.csv\")\n","df"],"metadata":{"id":"bA6aFnFmRyWv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Selected columns from your list\n","# df = df_cleaned\n","selected_columns = ['NAICS', 'Term', 'NoEmp', 'NewExist', 'CreateJob',\n","                   'RetainedJob', 'UrbanRural', 'RevLineCr', 'LowDoc',\n","                   'DisbursementGross', 'BalanceGross', 'ChgOffPrinGr',\n","                   'GrAppv', 'SBA_Appv', 'DaysToDisbursement', 'Industry',\n","                   'Minority', 'MIS_Status']\n","\n","# 1. Check data types\n","print(\"Data Types of Selected Columns:\")\n","print(\"-\" * 50)\n","print(df[selected_columns].dtypes)\n","\n","# 2. Categorize variables\n","numerical_continuous = []\n","numerical_discrete = []\n","categorical = []\n","\n","for column in selected_columns:\n","    # Get unique values\n","    unique_count = df[column].nunique()\n","    dtype = df[column].dtype\n","\n","    # Categorize based on data type and unique values\n","    if dtype in ['int64', 'float64']:\n","        if unique_count <= 25:  # Threshold for discrete vs continuous\n","            numerical_discrete.append(column)\n","        else:\n","            numerical_continuous.append(column)\n","    else:\n","        categorical.append(column)\n","\n","# Print categorization\n","print(\"\\nVariable Categorization:\")\n","print(\"-\" * 50)\n","print(\"\\nNumerical Continuous Variables:\")\n","for var in numerical_continuous:\n","    print(f\"{var}: {df[var].nunique()} unique values\")\n","\n","print(\"\\nNumerical Discrete Variables:\")\n","for var in numerical_discrete:\n","    print(f\"{var}: {df[var].nunique()} unique values\")\n","    print(f\"Unique values: {sorted(df[var].unique())}\")\n","\n","print(\"\\nCategorical Variables:\")\n","for var in categorical:\n","    print(f\"{var}: {df[var].nunique()} unique values\")\n","    if df[var].nunique() < 10:  # Show values only if there are few categories\n","        print(f\"Categories: {sorted(df[var].unique())}\")\n","\n","# 3. Check for missing values\n","print(\"\\nMissing Values:\")\n","print(\"-\" * 50)\n","missing_values = df[selected_columns].isnull().sum()\n","print(missing_values[missing_values > 0])\n","\n","# 4. Basic statistics for numerical variables\n","print(\"\\nNumerical Variables Summary:\")\n","print(\"-\" * 50)\n","print(df[numerical_continuous + numerical_discrete].describe())\n"],"metadata":{"id":"l5h4bNSR8BDu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# Convert date and filter for 1962-2014\n","df['ApprovalDate'] = pd.to_datetime(df['ApprovalDate'], format='%m/%d/%Y')\n","\n","# Create new DataFrame with only 1962-2014 data\n","df = df[(df['ApprovalDate'].dt.year >= 1962) & (df['ApprovalDate'].dt.year <= 2014)].copy()\n","\n","# Reset the index after filtering\n","df = df.reset_index(drop=True)\n","\n","# Verify the filtering\n","print(\"Dataset Information After Filtering:\")\n","print(\"-\" * 50)\n","print(f\"Total number of records: {len(df):,}\")\n","print(f\"Date range: {df['ApprovalDate'].dt.year.min()} to {df['ApprovalDate'].dt.year.max()}\")\n","print(\"\\nFirst few records:\")\n","print(df[['ApprovalDate', 'DisbursementGross', 'BalanceGross', 'MIS_Status']].head())"],"metadata":{"id":"29WHvu_38DfC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Selected columns from your list\n","selected_columns = ['NAICS', 'Term', 'NoEmp', 'NewExist', 'CreateJob',\n","                   'RetainedJob', 'UrbanRural', 'RevLineCr', 'LowDoc',\n","                   'DisbursementGross', 'BalanceGross', 'ChgOffPrinGr',\n","                   'GrAppv', 'SBA_Appv', 'DaysToDisbursement', 'Industry',\n","                   'Minority', 'MIS_Status']\n","\n","# 1. Check data types\n","print(\"Data Types of Selected Columns:\")\n","print(\"-\" * 50)\n","print(df[selected_columns].dtypes)\n","\n","# 2. Categorize variables\n","numerical_continuous = []\n","numerical_discrete = []\n","categorical = []\n","\n","for column in selected_columns:\n","    # Get unique values\n","    unique_count = df[column].nunique()\n","    dtype = df[column].dtype\n","\n","    # Categorize based on data type and unique values\n","    if dtype in ['int64', 'float64']:\n","        if unique_count < 20:  # Threshold for discrete vs continuous\n","            numerical_discrete.append(column)\n","        else:\n","            numerical_continuous.append(column)\n","    else:\n","        categorical.append(column)\n","\n","# Print categorization\n","print(\"\\nVariable Categorization:\")\n","print(\"-\" * 50)\n","print(\"\\nNumerical Continuous Variables:\")\n","for var in numerical_continuous:\n","    print(f\"{var}: {df[var].nunique()} unique values\")\n","\n","print(\"\\nNumerical Discrete Variables:\")\n","for var in numerical_discrete:\n","    print(f\"{var}: {df[var].nunique()} unique values\")\n","    print(f\"Unique values: {sorted(df[var].unique())}\")\n","\n","print(\"\\nCategorical Variables:\")\n","for var in categorical:\n","    print(f\"{var}: {df[var].nunique()} unique values\")\n","    if df[var].nunique() < 10:  # Show values only if there are few categories\n","        print(f\"Categories: {sorted(df[var].unique())}\")\n","\n","# Essential Data Quality Checks\n","print(f\"Missing Values in Key Features:\")\n","print(df[['DisbursementGross','Term','UrbanRural']].isnull().mean().round(2))\n","\n","print(\"\\nCritical Variable Ranges:\")\n","print(df[['DisbursementGross','Term','NoEmp']].agg(['min','median','max']))\n","\n","\n","# 3. Check for missing values\n","print(\"\\nMissing Values:\")\n","print(\"-\" * 50)\n","missing_values = df[selected_columns].isnull().sum()\n","print(missing_values[missing_values > 0])\n","\n","# 4. Basic statistics for numerical variables\n","print(\"\\nNumerical Variables Summary:\")\n","print(\"-\" * 50)\n","print(df[numerical_continuous + numerical_discrete].describe())\n"],"metadata":{"id":"oiJugUhS8GPE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# 1. Target Variable Summary\n","default_rate = (1 - df['MIS_Status'].mean()) * 100\n","print(f\"Default Rate: {default_rate:.1f}%\")\n","print(f\"Class Distribution:\\n{df['MIS_Status'].value_counts(normalize=True)}\")\n","\n","# 2. Key Categorical Analysis (Simplified)\n","key_vars = ['NewExist', 'RevLineCr', 'UrbanRural']\n","fig, ax = plt.subplots(1,3, figsize=(18,5))\n","\n","for i, var in enumerate(key_vars):\n","    df.groupby(var)['MIS_Status'].mean().mul(100).plot.bar(ax=ax[i])\n","    ax[i].set_title(f'Default Rate by {var}')\n","    ax[i].set_ylabel('Default Rate (%)')\n","\n","plt.tight_layout()\n","\n","# 3. Loan Amount Analysis (Critical Insight)\n","plt.figure(figsize=(12,6))\n","sns.boxplot(x='NewExist', y='DisbursementGross', hue='MIS_Status',\n","            data=df, showfliers=False)\n","plt.yscale('log')\n","plt.title('Loan Amount Distribution by Business Type')\n","plt.ylabel('Loan Amount (Log Scale)')"],"metadata":{"id":"fnIBgf0D8IZ-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.preprocessing import LabelEncoder\n","from scipy.stats import chi2_contingency\n","\n","sns.set_palette(\"husl\")  # Optional\n","\n","# Load your data first (e.g., df = pd.read_csv('SBAnational_clean.csv'))\n","\n","# Define features\n","numerical_features = ['Term', 'NoEmp', 'CreateJob', 'RetainedJob',\n","                      'DisbursementGross', 'GrAppv', 'SBA_Appv',\n","                      'DaysToDisbursement']\n","categorical_features = ['NewExist', 'UrbanRural', 'RevLineCr', 'LowDoc',\n","                        'Industry', 'Minority']\n","\n","# 1. Correlation Heatmap\n","corr_matrix = df[numerical_features + ['MIS_Status']].corr()\n","plt.figure(figsize=(10, 8))\n","sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0)\n","plt.title('Correlation Matrix of Numerical Features')\n","plt.tight_layout()\n","plt.savefig('correlation_heatmap.png')\n","plt.show()\n","\n","# 2. Chi-Squared Test for Categorical Features\n","chi2_results = []\n","for feature in categorical_features:\n","    table = pd.crosstab(df[feature], df['MIS_Status'])\n","    chi2, p_value, _, _ = chi2_contingency(table)\n","    chi2_results.append({'Feature': feature, 'Chi2': chi2, 'P-value': p_value})\n","chi2_df = pd.DataFrame(chi2_results).sort_values('Chi2', ascending=False)\n","print(\"\\nChi-Squared Test for Categorical Features\")\n","print(\"-\" * 50)\n","print(chi2_df)\n","\n","# 3. Feature Importance (Random Forest)\n","df_model = df[numerical_features + categorical_features + ['MIS_Status']].copy()\n","for col in categorical_features:\n","    df_model[col] = LabelEncoder().fit_transform(df_model[col].astype(str))\n","df_model.dropna(inplace=True)\n","\n","X = df_model.drop(columns=['MIS_Status'])\n","y = df_model['MIS_Status']\n","\n","rf = RandomForestClassifier(n_estimators=100, random_state=42)\n","rf.fit(X, y)\n","\n","feature_importance = pd.DataFrame({\n","    'Feature': X.columns,\n","    'Importance': rf.feature_importances_\n","}).sort_values('Importance', ascending=False)\n","\n","plt.figure(figsize=(10, 6))\n","sns.barplot(x='Importance', y='Feature', data=feature_importance)\n","plt.title('Feature Importance for Predicting Default (Random Forest)')\n","plt.tight_layout()\n","plt.savefig('feature_importance.png')\n","plt.show()\n","\n","print(\"\\nTop 10 Most Important Features:\")\n","print(feature_importance.head(10))\n"],"metadata":{"id":"hs4kB1h28L6K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# Convert date and filter for 1962-2014\n","df['ApprovalDate'] = pd.to_datetime(df['ApprovalDate'], format='%m/%d/%Y')\n","\n","# Create new DataFrame with only 1962-2014 data\n","df = df[(df['ApprovalDate'].dt.year >= 1962) & (df['ApprovalDate'].dt.year <= 2014)].copy()\n","\n","# Reset the index after filtering\n","df = df.reset_index(drop=True)\n","\n","# Verify the filtering\n","print(\"Dataset Information After Filtering:\")\n","print(\"-\" * 50)\n","print(f\"Total number of records: {len(df):,}\")\n","print(f\"Date range: {df['ApprovalDate'].dt.year.min()} to {df['ApprovalDate'].dt.year.max()}\")\n","print(\"\\nFirst few records:\")\n","print(df[['ApprovalDate', 'DisbursementGross', 'BalanceGross', 'MIS_Status']].head())"],"metadata":{"id":"filXqX0bTUgu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Question 2: Logistic Regression Modeling and Evaluation\n","Objective: Develop and assess a logistic regression model with varying probability thresholds, including performance metrics and validation techniques."],"metadata":{"id":"CJks1kxdLu4W"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Preprocess categorical variables\n","def preprocess_categorical_variables(df):\n","    df_processed = df.copy()\n","\n","    # 1. NewExist: Map 1 = Existing Business, 2 = New Business, all others (including NaN) to 0\n","    df_processed['NewExist_Cat'] = df_processed['NewExist'].map({\n","        1: 1,  # Existing Business\n","        2: 2   # New Business\n","    }).fillna(0).astype(int)\n","\n","    # 2. UrbanRural: Map 1 = Urban, 2 = Rural, all others (including NaN) to 0\n","    df_processed['UrbanRural_Cat'] = df_processed['UrbanRural'].map({\n","        1: 1,  # Urban\n","        2: 2   # Rural\n","    }).fillna(0).astype(int)\n","\n","    # 3. RevLineCr: Filter for Yes/No, map to binary (0=No, 1=Yes)\n","    df_processed = df_processed[df_processed['RevLineCr'].isin([16, 12])]\n","    df_processed['RevLineCr_Cat'] = df_processed['RevLineCr'].map({\n","        16: 1,  # Yes = 1\n","        12: 0   # No = 0\n","    })\n","\n","    # 4. LowDoc: Filter for Yes/No, map to binary (0=No, 1=Yes)\n","    df_processed = df_processed[df_processed['LowDoc'].isin([7, 4])]\n","    df_processed['LowDoc_Cat'] = df_processed['LowDoc'].map({\n","        7: 1,  # Yes = 1\n","        4: 0   # No = 0\n","    })\n","\n","    return df_processed\n","\n","# Preprocess the data\n","df_cleaned = preprocess_categorical_variables(df)\n","\n","# Handle NaN values by dropping rows with missing values in selected features\n","features_to_check = ['DisbursementGross', 'Term', 'NoEmp', 'CreateJob', 'RetainedJob',\n","                     'NewExist_Cat', 'UrbanRural_Cat', 'RevLineCr_Cat', 'LowDoc_Cat',\n","                     'MIS_Status']\n","df_cleaned = df_cleaned.dropna(subset=features_to_check)\n","\n","# Print data shapes\n","print(\"Data shape before preprocessing:\", df.shape)\n","print(\"Data shape after preprocessing and NaN removal:\", df_cleaned.shape)\n","\n","# Print value counts for categorical variables\n","print(\"\\nDistribution of categorical variables after preprocessing:\")\n","for col in ['NewExist_Cat', 'UrbanRural_Cat', 'RevLineCr_Cat', 'LowDoc_Cat']:\n","    print(f\"\\n{col}:\")\n","    counts = df_cleaned[col].value_counts()\n","    print(counts.rename({0: '0 (Other)', 1: '1 (Existing/Urban/Yes)', 2: '2 (New/Rural)'} if col in ['NewExist_Cat', 'UrbanRural_Cat'] else {0: '0 (No)', 1: '1 (Yes)'}))\n","    print(f\"Default Rate by {col}:\")\n","    default_rates = df_cleaned.groupby(col)['MIS_Status'].agg(['count', lambda x: (1-x.mean())*100])\n","    default_rates.columns = ['Count', 'Default Rate %']\n","    if col in ['NewExist_Cat', 'UrbanRural_Cat']:\n","        default_rates.index = default_rates.index.map({0: '0 (Other)', 1: '1 (Existing/Urban)', 2: '2 (New/Rural)'})\n","    else:\n","        default_rates.index = default_rates.index.map({0: '0 (No)', 1: '1 (Yes)'})\n","    print(default_rates.round(2))\n","\n","# Prepare features for modeling\n","def prepare_features_for_modeling(df):\n","    # Create dummy variables for non-binary categorical features\n","    categorical_features = ['NewExist_Cat', 'UrbanRural_Cat']\n","    df_dummy = pd.get_dummies(df, columns=categorical_features, dtype=int)\n","\n","    # Select numerical features\n","    numerical_features = ['DisbursementGross', 'Term', 'NoEmp', 'CreateJob', 'RetainedJob']\n","\n","    # Select binary categorical features\n","    binary_features = ['RevLineCr_Cat', 'LowDoc_Cat']\n","\n","    # Combine numerical and categorical features\n","    feature_columns = numerical_features + binary_features + \\\n","                     [col for col in df_dummy.columns if any(cat in col for cat in categorical_features)]\n","\n","    X = df_dummy[feature_columns]\n","    y = 1 - df_dummy['MIS_Status']  # Convert to 1 for default, 0 for non-default\n","\n","    return X, y\n","\n","# Prepare features\n","X, y = prepare_features_for_modeling(df_cleaned)\n","\n","print(\"\\nFeatures used in the model:\")\n","print(X.columns.tolist())\n","\n","# Scale numerical features\n","scaler = StandardScaler()\n","features_to_scale = ['DisbursementGross', 'Term', 'NoEmp', 'CreateJob', 'RetainedJob']\n","X_scaled = X.copy()\n","X_scaled[features_to_scale] = scaler.fit_transform(X[features_to_scale])\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, y,\n","                                                    test_size=0.3,\n","                                                    random_state=42,\n","                                                    stratify=y)\n","\n","# Function to evaluate model performance\n","def evaluate_model(y_true, y_pred_proba, threshold):\n","    y_pred = (y_pred_proba >= threshold).astype(int)\n","    cm = confusion_matrix(y_true, y_pred)\n","    tn, fp, fn, tp = cm.ravel()\n","\n","    # Calculate metrics\n","    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0  # Sensitivity/Recall\n","    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0  # False Positive Rate\n","    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n","    accuracy = (tp + tn) / (tp + tn + fp + fn)\n","    f1 = 2 * (precision * tpr) / (precision + tpr) if (precision + tpr) > 0 else 0\n","\n","    # Plot confusion matrix\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n","    plt.title(f'Confusion Matrix - Threshold: {threshold}')\n","    plt.ylabel('True Label (1=Default)')\n","    plt.xlabel('Predicted Label (1=Default)')\n","    plt.savefig(f'confusion_matrix_threshold_{threshold}.png')\n","\n","    return {\n","        'Threshold': threshold,\n","        'Accuracy': accuracy,\n","        'TPR (Sensitivity)': tpr,\n","        'FPR': fpr,\n","        'Precision': precision,\n","        'F1 Score': f1\n","    }\n","\n","# Fit logistic regression\n","model = LogisticRegression(solver='lbfgs', random_state=42, max_iter=2000)\n","model.fit(X_train, y_train)\n","\n","# Get predictions\n","y_train_pred_proba = model.predict_proba(X_train)[:, 1]\n","y_test_pred_proba = model.predict_proba(X_test)[:, 1]\n","\n","# Evaluate different thresholds\n","thresholds = [0.1, 0.2, 0.35, 0.5]\n","train_results = []\n","test_results = []\n","\n","print(\"\\nModel Performance:\")\n","print(\"-\" * 50)\n","\n","for threshold in thresholds:\n","    train_metrics = evaluate_model(y_train, y_train_pred_proba, threshold)\n","    test_metrics = evaluate_model(y_test, y_test_pred_proba, threshold)\n","\n","    print(f\"\\nThreshold: {threshold}\")\n","    print(\"\\nTraining Set Metrics:\")\n","    for metric, value in train_metrics.items():\n","        print(f\"{metric}: {value:.3f}\")\n","\n","    print(\"\\nTest Set Metrics:\")\n","    for metric, value in test_metrics.items():\n","        print(f\"{metric}: {value:.3f}\")\n","\n","    train_results.append(train_metrics)\n","    test_results.append(test_metrics)\n","\n","# Cross-validation\n","cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n","cv_scores = cross_val_score(model, X_scaled, y, cv=cv, scoring='roc_auc')\n","print(\"\\nCross-validation Results:\")\n","print(f\"ROC AUC scores: {cv_scores.round(3)}\")\n","print(f\"Mean ROC AUC: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})\")\n","\n","# Plot ROC curve\n","fpr, tpr, _ = roc_curve(y_test, y_test_pred_proba)\n","roc_auc = auc(fpr, tpr)\n","\n","plt.figure(figsize=(10, 8))\n","plt.plot(fpr, tpr, color='darkorange', lw=2,\n","         label=f'ROC curve (AUC = {roc_auc:.3f})')\n","plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic (ROC) Curve')\n","plt.legend(loc=\"lower right\")\n","plt.savefig('roc_curve.png')\n","\n","# Feature importance analysis\n","feature_importance = pd.DataFrame({\n","    'Feature': X.columns,\n","    'Importance': np.abs(model.coef_[0])\n","})\n","feature_importance = feature_importance.sort_values('Importance', ascending=False)\n","\n","print(\"\\nFeature Importance:\")\n","print(feature_importance)\n","\n","# ROC and AUC explanation\n","print(\"\\nROC and AUC Explanation:\")\n","print(\"-\" * 50)\n","print(\"The ROC curve plots the True Positive Rate (TPR, or sensitivity) against the False Positive Rate (FPR) across all thresholds.\")\n","print(\"TPR measures the proportion of actual defaults correctly identified (TP / (TP + FN)).\")\n","print(\"FPR measures the proportion of non-defaults incorrectly classified as defaults (FP / (FP + TN)).\")\n","print(\"The AUC quantifies the model’s ability to distinguish defaults from non-defaults:\")\n","print(\"- AUC = 0.5: No discrimination (random guessing).\")\n","print(\"- AUC > 0.7: Good discrimination.\")\n","print(\"- AUC > 0.9: Excellent discrimination.\")\n","print(f\"Our model’s test AUC (~{roc_auc:.3f}) indicates its overall performance.\")\n"],"metadata":{"id":"qFTVevoeQLp7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","import seaborn as sns\n","\n","# Style\n","plt.style.use(\"ggplot\")  # Try using a different style like 'ggplot' or 'bmh'\n","sns.set_context(\"notebook\")\n","\n","# 1. Performance comparison across thresholds\n","thresholds = [0.1, 0.2, 0.35, 0.5]\n","\n","# All variables (Test)\n","all_vars = {\n","    \"Accuracy\": [0.557, 0.769, 0.838, 0.842],\n","    \"TPR\": [0.908, 0.819, 0.547, 0.244],\n","    \"FPR\": [0.520, 0.242, 0.098, 0.027],\n","    \"Precision\": [0.278, 0.427, 0.553, 0.669],\n","    \"F1 Score\": [0.426, 0.562, 0.550, 0.358]\n","}\n","\n","# Selected variables (Test)\n","sel_vars = {\n","    \"Accuracy\": [0.445, 0.703, 0.785, 0.785],\n","    \"TPR\": [0.964, 0.878, 0.659, 0.394],\n","    \"FPR\": [0.740, 0.360, 0.170, 0.075],\n","    \"Precision\": [0.318, 0.466, 0.582, 0.653],\n","    \"F1 Score\": [0.478, 0.609, 0.618, 0.492]\n","}\n","\n","metrics = [\"Accuracy\", \"TPR\", \"FPR\", \"Precision\", \"F1 Score\"]\n","\n","# Plot\n","fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n","axes = axes.ravel()\n","\n","for i, metric in enumerate(metrics):\n","    axes[i].plot(thresholds, all_vars[metric], label='All Variables', marker='o', linewidth=2)\n","    axes[i].plot(thresholds, sel_vars[metric], label='Selected Variables', marker='s', linewidth=2)\n","    axes[i].set_title(f'{metric} vs Threshold', fontsize=14)\n","    axes[i].set_xlabel('Threshold')\n","    axes[i].set_ylabel(metric)\n","    axes[i].legend()\n","    axes[i].grid(True)\n","\n","# Hide the 6th subplot\n","axes[-1].axis('off')\n","\n","plt.tight_layout()\n","plt.suptitle(\"Model Performance Comparison: All vs Selected Variables\", fontsize=16, y=1.02)\n","\n","# Save the figure before showing it\n","plt.savefig('performance_comparison.png')\n","\n","# Display the plot\n","plt.show()"],"metadata":{"id":"2ffW8L0IUtyT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Group feature importance function\n","def group_feature_importance_ascending(feature_names, importances):\n","    importance_df = pd.DataFrame({\n","        'Feature': feature_names,\n","        'Importance': np.abs(importances)\n","    })\n","\n","    # Define grouping logic for dummy variables\n","    grouped = {}\n","    for _, row in importance_df.iterrows():\n","        feature = row['Feature']\n","        importance = row['Importance']\n","\n","        # Extract base name before the last underscore if it's a dummy var\n","        if '_Cat_' in feature:\n","            base = feature.split('_Cat_')[0] + '_Cat'\n","        else:\n","            base = feature\n","\n","        grouped[base] = grouped.get(base, 0) + importance\n","\n","    # Convert to DataFrame and sort by importance\n","    grouped_df = pd.DataFrame(list(grouped.items()), columns=['Feature Group', 'Total Importance'])\n","    grouped_df = grouped_df.sort_values('Total Importance', ascending=True)\n","    return grouped_df\n","\n","# Grouping for the 'all variables' and 'selected variables' importance\n","all_features = ['Term', 'UrbanRural_Cat_0', 'LowDoc_Cat', 'NewExist_Cat_0', 'CreateJob',\n","                'RevLineCr_Cat', 'RetainedJob', 'NoEmp', 'NewExist_Cat_1',\n","                'UrbanRural_Cat_2', 'NewExist_Cat_2', 'UrbanRural_Cat_1', 'DisbursementGross']\n","all_importances = [1.95, 1.20, 1.07, 0.82, 0.74, 0.68, 0.61, 0.41, 0.31, 0.29, 0.25, 0.12, 0.06]\n","\n","sel_features = ['Term', 'RevLineCr_1', 'NoEmp', 'GrAppv', 'SBA_Appv', 'UrbanRural_1', 'RetainedJob',\n","                'DisbursementGross', 'CreateJob', 'LowDoc_1', 'NewExist_1.0']\n","sel_importances = [2.14, 0.39, 0.38, 0.25, 0.20, 0.18, 0.08, 0.06, 0.06, 0.04, 0.01]\n","\n","# Group feature importance for all variables and selected variables\n","grouped_all = group_feature_importance_ascending(all_features, all_importances)\n","grouped_selected = group_feature_importance_ascending(sel_features, sel_importances)\n","\n","# Combine both grouped DataFrames into one for comparison\n","feat_all_grouped = pd.DataFrame({\n","    \"Feature Group\": grouped_all['Feature Group'],\n","    \"Importance\": grouped_all['Total Importance'],\n","    \"Model\": \"All Variables\"\n","})\n","\n","feat_sel_grouped = pd.DataFrame({\n","    \"Feature Group\": grouped_selected['Feature Group'],\n","    \"Importance\": grouped_selected['Total Importance'],\n","    \"Model\": \"Selected Variables\"\n","})\n","\n","# Combine both DataFrames into a single DataFrame\n","feature_importance_comparison = pd.concat([feat_all_grouped, feat_sel_grouped])\n","\n","# Plot the comparison of feature importance for grouped variables\n","plt.figure(figsize=(12, 8))\n","sns.barplot(x='Importance', y='Feature Group', hue='Model', data=feature_importance_comparison, palette='viridis')\n","plt.title('Grouped Feature Importance Comparison (All vs. Selected Variables)', fontsize=16)\n","plt.xlabel('Total Absolute Coefficient Value', fontsize=12)\n","plt.ylabel('Feature Group', fontsize=12)\n","plt.tight_layout()\n","plt.savefig('grouped_feature_importance_comparison.png')\n","plt.show()"],"metadata":{"id":"Pl2IQYrT3A9Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Question 3: Alternative Machine Learning Models and Comparative Analysis\n","Objective: Implement and evaluate three alternative machine learning models, comparing their performance against the logistic regression model."],"metadata":{"id":"hZPJRdo9LuyZ"}},{"cell_type":"code","source":["%matplotlib inline\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","from xgboost import XGBClassifier\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import confusion_matrix, roc_curve, auc\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Preprocess categorical variables\n","def preprocess_categorical_variables(df):\n","    df_processed = df.copy()\n","\n","    # Map NewExist to single feature: 1 = Existing, 2 = New, 0 = Other\n","    df_processed['NewExist_Cat'] = df_processed['NewExist'].map({\n","        1: 1,  # Existing Business\n","        2: 2   # New Business\n","    }).fillna(0).astype(int)\n","\n","    # Map UrbanRural to single feature: 1 = Urban, 2 = Rural, 0 = Other\n","    df_processed['UrbanRural_Cat'] = df_processed['UrbanRural'].map({\n","        1: 1,  # Urban\n","        2: 2   # Rural\n","    }).fillna(0).astype(int)\n","\n","    # Filter and map RevLineCr: 1 = Yes, 0 = No\n","    df_processed = df_processed[df_processed['RevLineCr'].isin([16, 12])]\n","    df_processed['RevLineCr_Cat'] = df_processed['RevLineCr'].map({\n","        16: 1,  # Yes\n","        12: 0   # No\n","    })\n","\n","    # Filter and map LowDoc: 1 = Yes, 0 = No\n","    df_processed = df_processed[df_processed['LowDoc'].isin([7, 4])]\n","    df_processed['LowDoc_Cat'] = df_processed['LowDoc'].map({\n","        7: 1,  # Yes\n","        4: 0   # No\n","    })\n","\n","    return df_processed\n","\n","# Preprocess the data\n","df_cleaned = preprocess_categorical_variables(df)\n","\n","# Handle NaN values\n","features_to_check = ['DisbursementGross', 'Term', 'NoEmp', 'CreateJob', 'RetainedJob',\n","                     'NewExist_Cat', 'UrbanRural_Cat', 'RevLineCr_Cat', 'LowDoc_Cat',\n","                     'MIS_Status', 'SBA_Appv', 'GrAppv']\n","df_cleaned = df_cleaned.dropna(subset=features_to_check)\n","\n","# Print data shapes\n","print(\"Data shape before preprocessing:\", df.shape)\n","print(\"Data shape after preprocessing and NaN removal:\", df_cleaned.shape)\n","\n","# Determine test size\n","# If df is less than 400 thousand parameters use 10% of the data\n","dataset_size = df_cleaned.shape[0]\n","test_size = 0.3 if dataset_size < 400000 else 0.1\n","print(\"Using test size: {}% (dataset size: {})\".format(test_size*100, dataset_size))\n","\n","# Prepare features for modeling\n","def prepare_features_for_modeling(df):\n","    numerical_features = ['DisbursementGross', 'Term', 'NoEmp', 'CreateJob', 'RetainedJob', 'SBA_Appv', 'GrAppv']\n","    categorical_features = ['NewExist_Cat', 'UrbanRural_Cat']\n","    binary_features = ['RevLineCr_Cat', 'LowDoc_Cat']\n","\n","    feature_columns = numerical_features + categorical_features + binary_features\n","\n","    X = df[feature_columns]\n","    y = 1 - df['MIS_Status']  # 1 = Default, 0 = Non-default\n","\n","    return X, y\n","\n","# Prepare features\n","X, y = prepare_features_for_modeling(df_cleaned)\n","\n","print(\"\\nFeatures used in the model:\")\n","print(X.columns.tolist())\n","\n","# Scale numerical features\n","# To make all the numerical features on the same scale\n","scaler = StandardScaler()\n","features_to_scale = ['DisbursementGross', 'Term', 'NoEmp', 'CreateJob', 'RetainedJob', 'SBA_Appv', 'GrAppv']\n","X_scaled = X.copy()\n","X_scaled[features_to_scale] = scaler.fit_transform(X[features_to_scale])\n","\n","# Split data\n","X_train, X_test, y_train, y_test = train_test_split(X_scaled, y,\n","                                                    test_size=test_size,\n","                                                    random_state=42,\n","                                                    stratify=y)\n","\n","# Function to evaluate model performance\n","def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n","    model.fit(X_train, y_train)\n","    y_test_pred_proba = model.predict_proba(X_test)[:, 1]\n","\n","    thresholds = [0.1, 0.2, 0.35, 0.5]\n","    test_results = []\n","\n","    for threshold in thresholds:\n","        y_pred = (y_test_pred_proba >= threshold).astype(int)\n","        cm = confusion_matrix(y_test, y_pred)\n","        tn, fp, fn, tp = cm.ravel()\n","\n","        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n","        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n","        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n","        accuracy = (tp + tn) / (tp + tn + fp + fn)\n","        f1 = 2 * (precision * tpr) / (precision + tpr) if (precision + tpr) > 0 else 0\n","\n","        test_results.append({\n","            'Threshold': threshold,\n","            'Accuracy': accuracy,\n","            'TPR (Sensitivity)': tpr,\n","            'FPR': fpr,\n","            'Precision': precision,\n","            'F1 Score': f1\n","        })\n","\n","    # Cross-validation\n","    cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n","    cv_scores = cross_val_score(model, X_scaled, y, cv=cv, scoring='roc_auc')\n","\n","    # ROC AUC\n","    fpr, tpr, _ = roc_curve(y_test, y_test_pred_proba)\n","    roc_auc = auc(fpr, tpr)\n","\n","    # Feature importance\n","    feature_importance = model.feature_importances_ if hasattr(model, 'feature_importances_') else None\n","\n","    return test_results, roc_auc, cv_scores, feature_importance, fpr, tpr\n","\n","# Define models and hyperparameters\n","models = {\n","    'DecisionTree': {\n","        'model': DecisionTreeClassifier(random_state=42),\n","        'param_name': 'max_depth',\n","        'param_values': [3, 4, 5, 6, 7, 8, 10, 12, 15, 20] # testing till different depths of the tree\n","    },\n","    'RandomForest': {\n","        'model': RandomForestClassifier(random_state=42, n_estimators=50),# lowering the estimators to save the running time\n","        'param_name': 'max_depth',\n","        'param_values': [3, 5, 10, 15, 20]\n","    },\n","    'XGBoost': {\n","        'model': XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n","        'param_name': 'max_depth',\n","        'param_values': [3, 5, 7, 10]\n","    }\n","}\n","\n","# Evaluate all models\n","all_results = {}\n","\n","for model_name, model_info in models.items():\n","    print(\"\\nEvaluating {}...\".format(model_name))\n","    param_results = []\n","\n","    for param_value in model_info['param_values']:\n","        model = model_info['model']\n","        setattr(model, model_info['param_name'], param_value)\n","\n","        results, roc_auc, cv_scores, feature_importance, fpr, tpr = evaluate_model(\n","            model, X_train, X_test, y_train, y_test, model_name\n","        )\n","\n","        param_results.append({\n","            'param_value': param_value,\n","            'test_results': results,\n","            'roc_auc': roc_auc,\n","            'cv_scores': cv_scores,\n","            'feature_importance': feature_importance,\n","            'fpr': fpr,\n","            'tpr': tpr\n","        })\n","\n","    # Find best parameter based on F1 score at threshold 0.2\n","    best_f1 = -1\n","    best_param = None\n","    best_results = None\n","    best_auc = None\n","    best_cv_scores = None\n","    best_feature_importance = None\n","    best_fpr = None\n","    best_tpr = None\n","\n","    for result in param_results:\n","        thresh_02 = next(r for r in result['test_results'] if r['Threshold'] == 0.2)\n","        f1_score = thresh_02['F1 Score']\n","        if f1_score > best_f1:\n","            best_f1 = f1_score\n","            best_param = result['param_value']\n","            best_results = result['test_results']\n","            best_auc = result['roc_auc']\n","            best_cv_scores = result['cv_scores']\n","            best_feature_importance = result['feature_importance']\n","            best_fpr = result['fpr']\n","            best_tpr = result['tpr']\n","\n","    all_results[model_name] = {\n","        'param_results': param_results,\n","        'best_param': best_param,\n","        'best_f1': best_f1,\n","        'best_results': best_results,\n","        'best_auc': best_auc,\n","        'best_cv_scores': best_cv_scores,\n","        'best_feature_importance': best_feature_importance,\n","        'best_fpr': best_fpr,\n","        'best_tpr': best_tpr\n","    }\n","\n","    # Print detailed results for each parameter\n","    print(\"\\nDetailed {} Results:\".format(model_name))\n","    print(\"-\" * 50)\n","    for result in param_results:\n","        param = result['param_value']\n","        print(\"\\n{}: {}\".format(model_info['param_name'], param))\n","        print(\"Test AUC: {:.3f}\".format(result['roc_auc']))\n","        print(\"Mean CV AUC: {:.3f} (+/- {:.3f})\".format(result['cv_scores'].mean(), result['cv_scores'].std() * 2))\n","        print(\"Test Set Metrics:\")\n","        for thresh_result in result['test_results']:\n","            print(\"  Threshold: {}\".format(thresh_result['Threshold']))\n","            for metric, value in thresh_result.items():\n","                print(\"    {}: {:.3f}\".format(metric, value))\n","\n","    # Print best parameter\n","    print(\"\\nBest {}: {} (F1 Score at Threshold 0.2: {:.3f})\".format(model_info['param_name'], best_param, best_f1))\n","\n","    # Print and plot feature importance for best parameter\n","    if best_feature_importance is not None:\n","        print(\"\\nFeature Importance for Best {} ({}={}):\".format(model_name, model_info['param_name'], best_param))\n","        print(\"-\" * 50)\n","        feature_importance_df = pd.DataFrame({\n","            'Feature': X.columns,\n","            'Importance': best_feature_importance\n","        }).sort_values(by='Importance', ascending=False)\n","        print(feature_importance_df)\n","\n","        plt.figure(figsize=(10, 6))\n","        sns.barplot(x='Importance', y='Feature', data=feature_importance_df)\n","        plt.title('Feature Importance for {} ({}={})'.format(model_name, model_info['param_name'], best_param))\n","        plt.show()\n","\n","    # Plot metrics vs parameter values (threshold = 0.2)\n","    metrics = ['F1 Score', 'Accuracy', 'TPR (Sensitivity)', 'FPR', 'Precision']\n","    metric_values = {metric: [] for metric in metrics}\n","\n","    for result in param_results:\n","        thresh_02 = next(r for r in result['test_results'] if r['Threshold'] == 0.2)\n","        for metric in metrics:\n","            metric_values[metric].append(thresh_02[metric])\n","\n","    for metric in metrics:\n","        plt.figure(figsize=(8, 6))\n","        plt.plot(model_info['param_values'], metric_values[metric], marker='o')\n","        plt.xlabel(model_info['param_name'])\n","        plt.ylabel(metric)\n","        plt.title('{}: {} vs {} (Threshold = 0.2)'.format(model_name, metric, model_info['param_name']))\n","        plt.grid(True)\n","        plt.show()\n","\n","    # Plot metrics vs thresholds for best parameter\n","    thresholds = [0.1, 0.2, 0.35, 0.5]\n","    for metric in metrics:\n","        plt.figure(figsize=(8, 6))\n","        metric_vals = [r[metric] for r in best_results]\n","        plt.plot(thresholds, metric_vals, marker='o')\n","        plt.xlabel('Threshold')\n","        plt.ylabel(metric)\n","        plt.title('{} ({}={}): {} vs Threshold'.format(model_name, model_info['param_name'], best_param, metric))\n","        plt.grid(True)\n","        plt.show()\n","\n","# Plot ROC curves for all models (best parameters)\n","plt.figure(figsize=(10, 6))\n","for model_name, result in all_results.items():\n","    plt.plot(result['best_fpr'], result['best_tpr'], lw=2,\n","             label='{} (AUC = {:.3f})'.format(model_name, result['best_auc']))\n","plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC Curves for All Models')\n","plt.legend(loc=\"lower right\")\n","plt.show()\n","\n","# Print final summary\n","print(\"\\nFinal Summary for All Models:\")\n","print(\"=\" * 50)\n","for model_name, result in all_results.items():\n","    print(\"\\n{} (Best {}={}):\".format(model_name, models[model_name]['param_name'], result['best_param']))\n","    print(\"-\" * 50)\n","    print(\"Test AUC: {:.3f}\".format(result['best_auc']))\n","    print(\"Mean CV AUC: {:.3f} (+/- {:.3f})\".format(result['best_cv_scores'].mean(), result['best_cv_scores'].std() * 2))\n","    for thresh_result in result['best_results']:\n","        print(\"\\nThreshold: {}\".format(thresh_result['Threshold']))\n","        print(\"Test Set Metrics:\")\n","        for metric, value in thresh_result.items():\n","            print(\"  {}: {:.3f}\".format(metric, value))"],"metadata":{"id":"sbQEqd7nQLEv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Question 4: Evaluation of Unsupervised Learning Techniques\n","Objective: Assess the theoretical and empirical potential of unsupervised learning methods to enhance predictive modeling for loan default prediction."],"metadata":{"id":"l56a8LPnLuq7"}},{"cell_type":"markdown","source":["## PCA Part"],"metadata":{"id":"724fhdog6Wfw"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.impute import SimpleImputer\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import cross_val_score\n","from sklearn.linear_model import LogisticRegression\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Load the dataset\n","df = pd.read_csv(\" \")\n","\n","# Create target variable from MIS_Status (0 = default, 1 = not default)\n","df['Default'] = df['MIS_Status'].map({0: 'Defaulted', 1: 'Not Defaulted'})\n","\n","# Drop date columns and identifiers\n","df = df.drop(columns=['ApprovalDate', 'ChgOffDate', 'DisbursementDate', 'LoanNr_ChkDgt', 'Name'])\n","\n","# Select features available at application time\n","application_time_columns = [\n","    'Term', 'NoEmp', 'NewExist', 'CreateJob', 'RetainedJob', 'FranchiseCode',\n","    'UrbanRural', 'RevLineCr', 'LowDoc', 'GrAppv', 'SBA_Appv',\n","    'City', 'State', 'Zip', 'Bank', 'BankState', 'NAICS', 'Industry', 'Minority'\n","]\n","X = df[application_time_columns].copy()\n","y = df['Default']\n","\n","# Identify numerical and categorical columns\n","numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n","categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n","\n","# Preprocessing pipeline\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', Pipeline([\n","            ('imputer', SimpleImputer(strategy='median')),\n","            ('scaler', StandardScaler())\n","        ]), numerical_cols),\n","        ('cat', Pipeline([\n","            ('imputer', SimpleImputer(strategy='most_frequent')),\n","            ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n","        ]), categorical_cols)\n","    ])\n","\n","# Fit and transform the data\n","X_processed = preprocessor.fit_transform(X)\n","\n","# PCA with enough components to explain 95% variance (here, 10 for visualization)\n","pca = PCA(n_components=10)\n","X_pca = pca.fit_transform(X_processed)\n","\n","# Scree plot (Cumulative Explained Variance)\n","plt.figure(figsize=(10, 6))\n","plt.plot(\n","    range(1, len(pca.explained_variance_ratio_) + 1),\n","    np.cumsum(pca.explained_variance_ratio_), 'o-'\n",")\n","plt.axhline(y=0.95, color='r', linestyle='-')\n","plt.xlabel('Number of Components')\n","plt.ylabel('Cumulative Explained Variance')\n","plt.title('Scree Plot - Cumulative Explained Variance')\n","plt.grid(True)\n","plt.tight_layout()\n","plt.show()\n","\n","# First two PCs for visualization (PC1 vs PC2 scatter, color-coded by Default status)\n","pca_df = pd.DataFrame(X_pca[:, :2], columns=['PC1', 'PC2'])\n","pca_df['Default'] = y.reset_index(drop=True)\n","\n","color_mapping = {'Defaulted': 'red', 'Not Defaulted': 'blue'}\n","\n","plt.figure(figsize=(12, 8))\n","sns.scatterplot(\n","    x='PC1', y='PC2',\n","    hue='Default',\n","    data=pca_df,\n","    alpha=0.6,\n","    palette=color_mapping\n",")\n","plt.title(\"PCA of SBA Loan Data (PC1 vs PC2) by Default Status\")\n","plt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)\")\n","plt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)\")\n","plt.grid(True)\n","plt.legend(title='Default Status')\n","plt.tight_layout()\n","plt.show()\n","\n","def biplot(projected_data, loadings, feature_names, y_labels, scale=5):\n","    \"\"\"\n","    Creates a biplot showing PCA-projected data and feature loadings.\n","    Args:\n","        projected_data (array): PCA-transformed data (e.g., X_pca).\n","        loadings (array): PCA loadings matrix (components).\n","        feature_names (list): Names of original features.\n","        y_labels (Series): Default status labels for coloring.\n","        scale (float): Scaling factor for loadings arrows.\n","    \"\"\"\n","    plt.figure(figsize=(12, 8))\n","    # Use lighter colors for points\n","    color_dict = {'Defaulted': '#FF9999', 'Not Defaulted': '#87CEFA'}  # light red and light blue\n","    colors = [color_dict[val] for val in y_labels]\n","    plt.scatter(projected_data[:, 0], projected_data[:, 1],\n","                c=colors, alpha=0.5, edgecolor='k', s=40, label=None)\n","    # Plot feature loadings as arrows\n","    for i, feature in enumerate(feature_names):\n","        plt.arrow(0, 0, loadings[i, 0] * scale, loadings[i, 1] * scale,\n","                  color='black', alpha=0.8, head_width=0.2, length_includes_head=True)\n","        plt.text(loadings[i, 0] * scale * 1.18, loadings[i, 1] * scale * 1.18,\n","                 feature, color='black', ha='center', va='center', fontsize=10, weight='bold')\n","    plt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)\")\n","    plt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)\")\n","    plt.title(\"PCA Biplot of SBA Loan Data\")\n","    plt.grid(True, linestyle='--', alpha=0.6)\n","    # Custom legend for Defaulted/Not Defaulted\n","    from matplotlib.lines import Line2D\n","    legend_elements = [\n","        Line2D([0], [0], marker='o', color='w', label='Defaulted', markerfacecolor='#FF9999', markeredgecolor='k', markersize=10),\n","        Line2D([0], [0], marker='o', color='w', label='Not Defaulted', markerfacecolor='#87CEFA', markeredgecolor='k', markersize=10)\n","    ]\n","    plt.legend(handles=legend_elements, title='Default Status')\n","    plt.tight_layout()\n","    plt.show()\n","\n","\n","# Get feature names after preprocessing\n","feature_names = preprocessor.get_feature_names_out()\n","feature_names_clean = [name.split('__')[-1] for name in feature_names]\n","loadings = pca.components_.T[:, :2]  # First two components\n","\n","biplot(X_pca[:, :2], loadings, feature_names_clean, y.reset_index(drop=True), scale=15)\n","\n","\n","# Optional: Model evaluation with cross-validation using PCA features\n","y_binary = y.map({'Defaulted': 0, 'Not Defaulted': 1})\n","model = LogisticRegression(max_iter=1000)\n","scores = cross_val_score(model, X_pca, y_binary, cv=5, scoring='roc_auc')\n","print(f\"Average ROC-AUC with PCA: {np.mean(scores):.4f}\")\n"],"metadata":{"id":"BbKp9f9tQKhB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","# Number of top features to show\n","top_n = 14\n","\n","# Compute the sum of squared loadings for PC1 and PC2\n","loading_strength = np.sum(loadings**2, axis=1)\n","top_features_idx = np.argsort(loading_strength)[-top_n:]\n","\n","# Filter feature names and loadings\n","selected_features = [feature_names_clean[i] for i in top_features_idx]\n","selected_loadings = loadings[top_features_idx]\n"],"metadata":{"id":"44ztAtaI6d5s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from matplotlib.patheffects import withStroke\n","\n","def biplot(projected_data, loadings, feature_names, y_labels, scale=15, top_n=7):\n","    \"\"\"\n","    Clean, uncluttered PCA biplot: shows only top_n features by loading strength.\n","    \"\"\"\n","    plt.figure(figsize=(12, 8))\n","    # Lighter, more transparent points\n","    color_dict = {'Defaulted': '#FF9999', 'Not Defaulted': '#87CEFA'}\n","    colors = [color_dict[val] for val in y_labels]\n","    plt.scatter(projected_data[:, 0], projected_data[:, 1],\n","                c=colors, alpha=0.3, edgecolor='none', s=30, label=None)\n","\n","    # Select top_n features by loading strength\n","    loading_strength = np.sum(loadings**2, axis=1)\n","    top_features_idx = np.argsort(loading_strength)[-top_n:]\n","    selected_features = [feature_names[i] for i in top_features_idx]\n","    selected_loadings = loadings[top_features_idx]\n","\n","    # Draw arrows and labels\n","    for i, feature in enumerate(selected_features):\n","        x, y = selected_loadings[i, 0]*scale, selected_loadings[i, 1]*scale\n","        plt.arrow(0, 0, x, y, color='black', alpha=0.9, head_width=0.5, head_length=0.7, linewidth=2, length_includes_head=True)\n","        plt.text(x*1.10, y*1.10, feature, color='black', fontsize=13, weight='bold',\n","                 ha='center', va='center',\n","                 path_effects=[withStroke(linewidth=3, foreground=\"white\")])\n","\n","    plt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)\")\n","    plt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)\")\n","    plt.title(\"PCA Biplot of SBA Loan Data (Top Features Only)\")\n","    plt.grid(True, linestyle='--', alpha=0.6)\n","    # Custom legend\n","    from matplotlib.lines import Line2D\n","    legend_elements = [\n","        Line2D([0], [0], marker='o', color='w', label='Defaulted', markerfacecolor='#FF9999', markeredgecolor='k', markersize=10),\n","        Line2D([0], [0], marker='o', color='w', label='Not Defaulted', markerfacecolor='#87CEFA', markeredgecolor='k', markersize=10)\n","    ]\n","    plt.legend(handles=legend_elements, title='Default Status')\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Usage:\n","biplot(X_pca[:, :2], loadings, feature_names_clean, y.reset_index(drop=True), scale=15, top_n=7)\n"],"metadata":{"id":"mxurDO4Q6hZr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler\n","\n","# Assume X_processed is your preprocessed feature matrix\n","\n","# Fit PCA with enough components\n","pca_full = PCA()\n","X_pca_full = pca_full.fit_transform(X_processed)\n","\n","explained_var = pca_full.explained_variance_ratio_\n","cumulative_var = np.cumsum(explained_var)\n","num_components = np.arange(1, len(explained_var) + 1)\n","\n","plt.figure(figsize=(8,5))\n","plt.plot(num_components, cumulative_var, marker='o', color='blue', label='Cumulative Variance Explained')\n","plt.plot(num_components, explained_var, marker='x', color='orange', label='Individual Explained Variance')\n","plt.xlabel('Number of Principal Components')\n","plt.ylabel('Variance Explained')\n","plt.title('Variance Explained by PCA')\n","plt.legend()\n","plt.tight_layout()\n","plt.show()\n","\n"],"metadata":{"id":"5usoNzD86j_8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"l3FVclYR8pyJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Clustering"],"metadata":{"id":"2RxuqU8R6qt1"}},{"cell_type":"markdown","source":["K Means\n"],"metadata":{"id":"7s9CgL-_8oSU"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import silhouette_score\n","import matplotlib.pyplot as plt\n","\n","# Load your data\n","df = pd.read_csv(\"\")\n","\n","# Select relevant columns for clustering (exclude identifiers and dates)\n","clustering_columns = [\n","    'Term', 'NoEmp', 'NewExist', 'CreateJob', 'RetainedJob', 'FranchiseCode',\n","    'UrbanRural', 'RevLineCr', 'LowDoc', 'GrAppv', 'SBA_Appv',\n","    'DisbursementGross', 'BalanceGross', 'DaysToDisbursement', 'Minority'\n","]\n","X = df[clustering_columns].dropna()\n","\n","# Standardize the features\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X)\n"],"metadata":{"id":"Pej1UUDk6tQd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["inertia = []\n","k_range = range(1, 11)\n","for k in k_range:\n","    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n","    kmeans.fit(X)\n","    inertia.append(kmeans.inertia_)\n","optimal_k = 3\n","plt.figure(figsize=(8, 5))\n","plt.plot(k_range, inertia, 'o-')\n","plt.xlabel('Number of Clusters (k)')\n","plt.ylabel('Inertia')\n","plt.title('Elbow Method For Optimal k')\n","plt.grid(True)\n","# Highlight the optimal k\n","plt.axvline(x=optimal_k, color='red', linestyle='--', label=f'Optimal k = {optimal_k}')\n","plt.legend()\n","plt.show()\n"],"metadata":{"id":"vk5TaDSz6vY-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimal_k = 3\n","kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n","cluster_labels = kmeans.fit_predict(X)\n","X['Cluster'] = cluster_labels\n"],"metadata":{"id":"5iqX1nfT6xz3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.decomposition import PCA\n","import seaborn as sns\n","\n","pca = PCA(n_components=2)\n","X_pca = pca.fit_transform(X)\n","pca_df = pd.DataFrame(X_pca, columns=['PC1', 'PC2'])\n","pca_df['Cluster'] = cluster_labels\n","\n","plt.figure(figsize=(10, 7))\n","sns.scatterplot(x='PC1', y='PC2', hue='Cluster', data=pca_df, palette='viridis', alpha=0.7)\n","plt.title('K-means Clusters Visualized with PCA')\n","plt.xlabel('PC1')\n","plt.ylabel('PC2')\n","plt.grid(True)\n","plt.show()\n"],"metadata":{"id":"ewmMVok86z5U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Hierarchial Clustering"],"metadata":{"id":"j4iZtW4F64wt"}},{"cell_type":"code","source":["from sklearn.cluster import AgglomerativeClustering\n","import seaborn as sns\n","import scipy.cluster.hierarchy as sch\n","import matplotlib.pyplot as plt\n","\n","# Sample the data\n","sample_size = 500  # Adjust based on available memory/performance\n","X_sample = X_scaled[:sample_size]\n","\n","# Create dendrogram to help decide number of clusters\n","plt.figure(figsize=(12, 6))\n","dendrogram = sch.dendrogram(sch.linkage(X_sample, method='ward'))\n","plt.title(\"Dendrogram (Sampled Data)\")\n","plt.xlabel(\"Samples\")\n","plt.ylabel(\"Euclidean Distance\")\n","plt.show()\n","\n","\n","# Apply Agglomerative Clustering\n","hc = AgglomerativeClustering(n_clusters=4, metric='euclidean', linkage='ward')\n","y_hc = hc.fit_predict(X_sample)\n","\n","\n"],"metadata":{"id":"Wys_OF-k6-EL"},"execution_count":null,"outputs":[]}]}